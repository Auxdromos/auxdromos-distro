# .github/workflows/reusable-ci-template.yml
# Workflow riutilizzabile per build, test, package, deploy di moduli AuxDromos
name: Reusable AuxDromos CI/CD

permissions:
  actions: write
  id-token: write
  contents: read

on:
  workflow_call:
    # Definisci gli input che il workflow chiamante può passare
    inputs:
      java-version:
        description: 'Versione JDK da usare'
        required: false
        type: string
        default: '17'
      maven-profiles: # <-- NUOVO INPUT
        description: 'Profili Maven da attivare (es. -Psit,prod)'
        required: false
        type: string
        default: '-Psit' # Default per mantenere comportamento precedente
      artifact-retention-days:
        description: 'Numero di giorni dopo i quali gli artifact vengono eliminati'
        required: false
        type: number
        default: 7

    # Non sono più richiesti segreti AWS/EC2 dal chiamante
    secrets:
      GITHUB_PACKAGES_TOKEN:
        required: false
        description: 'Token per accedere ai repository GitHub privati'

# Imposta la regione AWS staticamente
env:
  AWS_REGION: us-east-1 # <-- IMPOSTA QUI LA TUA REGIONE STATICA

jobs:
  extract_module_info:
    name: Prepare - Extract Module Info
    runs-on: ubuntu-latest
    container: maven:3.8.5-openjdk-17
    outputs:
      module_name: ${{ steps.extract.outputs.MODULE_NAME }}
      version: ${{ steps.extract.outputs.VERSION }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Extract Info from pom.xml
        id: extract
        run: |
          echo "Estrazione delle informazioni dal pom.xml del repository chiamante..."
          if [ -f "pom.xml" ]; then
            echo "Usando Maven per estrarre artifactId e version..."
            MODULE_NAME=$(mvn help:evaluate -Dexpression=project.artifactId -q -DforceStdout)
            VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)
          else
            echo "ATTENZIONE: pom.xml non trovato nel repository chiamante."
            MODULE_NAME=$(basename ${{ github.repository }}) # Nome repo come fallback
            SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)
            VERSION="1.0.0-${SHORT_SHA}" # Versione di fallback
          fi

          if [[ -z "$MODULE_NAME" ]] || [[ -z "$VERSION" ]]; then
             echo "ERRORE: Impossibile estrarre MODULE_NAME o VERSION."
             exit 1
          fi

          echo "Modulo $MODULE_NAME, Versione $VERSION"
          echo "MODULE_NAME=$MODULE_NAME" >> $GITHUB_OUTPUT
          echo "VERSION=$VERSION" >> $GITHUB_OUTPUT

  check_version:
    name: Check Version Existence (Main Branch Only)
    runs-on: ubuntu-latest
    needs: extract_module_info
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Run Version Check Script
        run: |
          set -e
          set -o pipefail
          echo "Verifica della versione per il branch 'main'..."

          if [[ -z "$MODULE_NAME" ]] || [[ -z "$VERSION" ]]; then
            echo "ERRORE: MODULE_NAME ('$MODULE_NAME') o VERSION ('$VERSION') sono vuote."
            exit 1
          fi

          if [[ "$VERSION" == *"SNAPSHOT"* ]]; then
            echo "Errore: Versione '$VERSION' non valida in 'main' (SNAPSHOT non consentito)."
            exit 1
          fi

          ECR_REPO_NAME="auxdromos-$MODULE_NAME"
          echo "Controllo se il repository ECR '$ECR_REPO_NAME' esiste..."
          if ! aws ecr describe-repositories --repository-names "$ECR_REPO_NAME" --region "$AWS_REGION" > /dev/null 2>&1; then
            echo "ATTENZIONE: Repository ECR '$ECR_REPO_NAME' non esiste ancora; verrà creato più tardi."
          else
            echo "Repository ECR trovato. Controllo se la versione '$VERSION' è già presente..."
            if aws ecr describe-images --repository-name "$ECR_REPO_NAME" \
                                      --image-ids imageTag="$VERSION" \
                                      --region "$AWS_REGION" > /dev/null 2>&1; then
              echo "ERRORE: L'immagine '$ECR_REPO_NAME:$VERSION' è già presente."
              exit 1
            fi
          fi

          echo "Versione '$VERSION' valida per 'main'. Procedo..."

  build:
    name: Build Project
    runs-on: ubuntu-latest
    needs: [extract_module_info]
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Cache Maven dependencies
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: maven-${{ runner.os }}-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            maven-${{ runner.os }}-

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java-version }}
          distribution: 'corretto'
          cache: 'maven'

      - name: Build with Maven
        env:
          GH_PACKAGES_TOKEN: ${{ secrets.GITHUB_PACKAGES_TOKEN }}
          GITHUB_ACTOR: ${{ github.actor }}
        run: |
          echo "Build del modulo $MODULE_NAME versione $VERSION con profili: ${{ inputs.maven-profiles }}"
          echo "Using GitHub token for authentication with GitHub Packages"
          mvn clean package ${{ inputs.maven-profiles }} -DskipTests --settings settings.xml

      - name: Create Build Info
        run: |
          mkdir -p target
          cat > target/build-info.json <<EOF
          {
            "moduleName": "$MODULE_NAME",
            "version": "$VERSION",
            "buildDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "branch": "${{ github.ref_name }}",
            "commitHash": "${{ github.sha }}"
          }
          EOF
          echo "Contenuto build-info.json:"
          cat target/build-info.json

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: |
            target/*.jar
            target/distribution/
            target/build-info.json
          if-no-files-found: error
          retention-days: 1    # abbassa da default (90 giorni) a 1–5 giorni
  test:
    name: Test Project
    runs-on: ubuntu-latest
    needs: [extract_module_info, build]
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Cache Maven dependencies
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: maven-${{ runner.os }}-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            maven-${{ runner.os }}-

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java-version }}
          distribution: 'corretto'
          cache: 'maven'

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/build

      - name: Run Tests with Maven
        run: |
          echo "Test del modulo $MODULE_NAME versione $VERSION..."
          mvn test

  package_configs:
    name: Package Configuration Files (Main Branch Only)
    runs-on: ubuntu-latest
    needs: extract_module_info
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Install zip
        run: sudo apt-get update && sudo apt-get install -y zip

      - name: Create Config Package
        run: |
          set -x
          echo "Creazione pacchetto di configurazione $MODULE_NAME versione $VERSION..."
          mkdir -p dist
          FILES_TO_ZIP=""
          for DIR in aws docker scripts env; do
            if [ -d "$DIR" ]; then
              FILES_TO_ZIP="$FILES_TO_ZIP $DIR/"
              echo "Aggiungo directory $DIR al ZIP"
            fi
          done
          find . -maxdepth 1 \( -name '*.yml' -o -name '*.yaml' -o -name '*.properties' \) -print0 | while IFS= read -r -d $'\0' file; do
              if [ -f "$file" ]; then
                  BASENAME=$(basename "$file")
                  FILES_TO_ZIP="$FILES_TO_ZIP $BASENAME"
                  echo "Aggiungo file $BASENAME al ZIP"
              fi
          done

          if [ -n "$FILES_TO_ZIP" ]; then
            echo "Creazione ZIP con: $FILES_TO_ZIP"
            zip -r "dist/$MODULE_NAME-$VERSION.zip" $FILES_TO_ZIP
          else
            echo "AVVISO: Nessun file/directory di configurazione standard trovato da includere nel ZIP, genero ZIP vuoto"
            touch empty.txt
            zip -r "dist/$MODULE_NAME-$VERSION.zip" empty.txt
            rm empty.txt
          fi
          if [ -f "dist/$MODULE_NAME-$VERSION.zip" ]; then echo "File ZIP creato dist/$MODULE_NAME-$VERSION.zip"; else echo "ERRORE Il file ZIP non è stato creato"; exit 1; fi

          echo "{\"moduleName\":\"$MODULE_NAME\",\"version\":\"$VERSION\",\"buildDate\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"branch\":\"${{ github.ref_name }}\",\"commitHash\":\"${{ github.sha }}\"}" > dist/manifest.json

      - name: Upload config package artifact
        uses: actions/upload-artifact@v4
        with:
          name: config-package-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: dist/
          if-no-files-found: error
          retention-days: 1    # abbassa da default (90 giorni) a 1–5 giorni

  build_docker:
    name: Build and Push Docker Image (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, build]
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      ECR_REPOSITORY: auxdromos-${{ needs.extract_module_info.outputs.module_name }}
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/build

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Check for Dockerfile and Build/Push
        id: docker_build
        run: |
          if [ -f "Dockerfile" ]; then
            echo "Dockerfile trovato per $MODULE_NAME, procedo con build e push"

            aws ecr describe-repositories --repository-names "${ECR_REPOSITORY}" --region "${AWS_REGION}" > /dev/null 2>&1 || \
              (echo "Repository ECR '${ECR_REPOSITORY}' non esiste, lo creo..." && \
               aws ecr create-repository --repository-name "${ECR_REPOSITORY}" --region "${AWS_REGION}" && \
               echo "Repository ECR creato con successo.") || \
              (echo "Repository ECR '${ECR_REPOSITORY}' esiste già.")

            ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}
            IMAGE_TAG="${ECR_REGISTRY}/${ECR_REPOSITORY}:${VERSION}"

            echo "Building image: ${IMAGE_TAG}"
            DOCKER_BUILD_ARGS=""
            # Potresti recuperare BUILD_ARGS da SSM se necessario

            docker buildx build --push \
            --build-arg GH_PACKAGES_TOKEN=${{ secrets.GITHUB_PACKAGES_TOKEN }} \
            --build-arg GITHUB_ACTOR=${{ github.actor }} \
            -t "${IMAGE_TAG}" \
            --platform linux/amd64 .

            echo "Immagine Docker caricata con successo: ${IMAGE_TAG}"
            echo "docker_image_pushed=true" >> $GITHUB_OUTPUT
          else
            echo "Dockerfile non trovato per $MODULE_NAME nel repository chiamante, salto build e push Docker"
            echo "docker_image_pushed=false" >> $GITHUB_OUTPUT
          fi

  upload_to_s3:
    name: Upload Artifacts to S3
    runs-on: ubuntu-latest
    needs: [extract_module_info, build, package_configs]
    if: github.ref_name == 'main' && github.event_name == 'push'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name' # Esempio
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/build

      - name: Download config package artifact
        uses: actions/download-artifact@v4
        with:
          name: config-package-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/package

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Fetch S3 Bucket Name from Parameter Store
        id: get-s3-bucket
        run: |
          S3_BUCKET=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)
          if [[ -z "$S3_BUCKET" ]]; then echo "ERRORE: Valore vuoto per SSM_S3_BUCKET_PARAM"; exit 1; fi
          echo "S3_BUCKET_NAME=$S3_BUCKET" >> $GITHUB_ENV

      - name: Upload to S3
        env:
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }}
        run: |
          set -e
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            S3_PATH="${MODULE_NAME}/${VERSION}/"
          else
            echo "ERRORE: Upload S3 configurato solo per il branch 'main'."
            exit 1
          fi

          S3_URI="s3://${S3_BUCKET_NAME}/${S3_PATH}"
          echo "Uploading artifacts for $MODULE_NAME version $VERSION into ${S3_URI}"

          JAR_COUNT=$(find artifacts/build -maxdepth 1 -name '*.jar' | wc -l)
          if [ "$JAR_COUNT" -gt 0 ]; then
            echo "Uploading JAR files..."
            aws s3 cp artifacts/build/ "${S3_URI}" --recursive --exclude "*" --include "*.jar"
          else
            echo "Nessun file JAR trovato in artifacts/build/"
          fi

          if [ -d "artifacts/build/distribution/" ]; then
            echo "Uploading distribution files..."
            aws s3 cp artifacts/build/distribution/ "${S3_URI}distribution/" --recursive
          fi

          if [ -f "artifacts/build/build-info.json" ]; then
            echo "Uploading build-info..."
            aws s3 cp artifacts/build/build-info.json "${S3_URI}build-info.json"
          fi

          ZIP_FILE="artifacts/package/$MODULE_NAME-$VERSION.zip"
          if [ -f "$ZIP_FILE" ]; then
            echo "Uploading ZIP file $ZIP_FILE..."
            aws s3 cp "$ZIP_FILE" "${S3_URI}$MODULE_NAME-$VERSION.zip"
          else
            echo "ERRORE: Il file ZIP $ZIP_FILE non esiste. Correggi il job package_configs."
            exit 1
          fi

          echo "Verifica upload:"
          aws s3 ls "${S3_URI}" --recursive

  tag_latest:
    name: Tag Latest Version in S3 (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, upload_to_s3]
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name' # Esempio
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Fetch S3 Bucket Name from Parameter Store
        id: get-s3-bucket
        run: |
          S3_BUCKET=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)
          if [[ -z "$S3_BUCKET" ]]; then echo "ERRORE: Valore vuoto per SSM_S3_BUCKET_PARAM"; exit 1; fi
          echo "S3_BUCKET_NAME=$S3_BUCKET" >> $GITHUB_ENV

      - name: Create and Upload latest.json
        env:
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }}
        run: |
          set -e
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            LATEST_PATH="${MODULE_NAME}/latest.json"
            S3_BASE_PATH="${MODULE_NAME}/"
          else
            echo "ERRORE: Tag Latest configurato solo per il branch 'main'."
            exit 1
          fi

          S3_URI="s3://${S3_BUCKET_NAME}/${LATEST_PATH}"

          cat > latest.json <<EOF
          {
            "moduleName": "$MODULE_NAME",
            "latestVersion": "$VERSION",
            "updateDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "branch": "${{ github.ref_name }}",
            "commitHash": "${{ github.sha }}"
          }
          EOF

          echo "Tagging della versione $VERSION come 'latest' per $MODULE_NAME nel path $S3_BASE_PATH"
          aws s3 cp latest.json "${S3_URI}"
          echo "Contenuto di latest.json caricato:"
          cat latest.json

  # --- JOB cleanup_s3 RIMOSSO ---
  # Si assume l'uso di S3 Lifecycle Policies

  deploy_sit:
    name: Deploy to SIT Environment (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, upload_to_s3, build_docker] # Dipende ancora da upload_to_s3 per il deploy di 'distro'
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      SSM_EC2_USER_PARAM: '/github/sit/ec2_user'
      SSM_EC2_HOST_PARAM: '/github/sit/ec2_host'
      SSM_EC2_KEY_PARAM: '/github/sit/ec2_private_key'
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name'
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Fetch EC2 Details and S3 Bucket from Parameter Store
        id: fetch-secrets
        run: |
          set -e
          echo "Recupero parametri SSM..."
          EC2_USER_VAL=$(aws ssm get-parameter --name "${{ env.SSM_EC2_USER_PARAM }}" --query Parameter.Value --output text)
          EC2_HOST_VAL=$(aws ssm get-parameter --name "${{ env.SSM_EC2_HOST_PARAM }}" --query Parameter.Value --output text)
          EC2_KEY_VAL=$(aws ssm get-parameter --name "${{ env.SSM_EC2_KEY_PARAM }}" --with-decryption --query Parameter.Value --output text)
          S3_BUCKET_VAL=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)
          echo "Parametri recuperati."

          echo "Controllo valori recuperati..."
          if [[ -z "$EC2_USER_VAL" ]]; then echo "ERRORE: Valore vuoto per SSM_EC2_USER_PARAM"; exit 1; fi
          if [[ -z "$EC2_HOST_VAL" ]]; then echo "ERRORE: Valore vuoto per SSM_EC2_HOST_PARAM"; exit 1; fi
          if [[ -z "$EC2_KEY_VAL" ]]; then echo "ERRORE: Valore vuoto per SSM_EC2_KEY_PARAM (SecureString)"; exit 1; fi
          if [[ -z "$S3_BUCKET_VAL" ]]; then echo "ERRORE: Valore vuoto per SSM_S3_BUCKET_PARAM"; exit 1; fi
          echo "Valori non vuoti."

          echo "::add-mask::$EC2_KEY_VAL"

          echo "SSH_KEY_CONTENT<<EOF" >> $GITHUB_OUTPUT
          echo "$EC2_KEY_VAL" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "DEBUG: Valore EC2_HOST_VAL prima di GITHUB_ENV: ->${EC2_HOST_VAL}<-"
          echo "EC2_USER=$EC2_USER_VAL" >> $GITHUB_ENV
          echo "EC2_HOST=$EC2_HOST_VAL" >> $GITHUB_ENV
          echo "S3_BUCKET_NAME=$S3_BUCKET_VAL" >> $GITHUB_ENV
          echo "DEBUG: Variabili impostate in GITHUB_ENV."

          SSH_KEY_PATH=$(mktemp)
          echo "$EC2_KEY_VAL" > "$SSH_KEY_PATH"
          chmod 600 "$SSH_KEY_PATH"
          echo "SSH_KEY_PATH=$SSH_KEY_PATH" >> $GITHUB_OUTPUT

      - name: Setup SSH Agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ steps.fetch-secrets.outputs.SSH_KEY_CONTENT }}

      - name: Add EC2 Host to Known Hosts
        run: |
          echo "DEBUG: Valore EC2_HOST all'inizio dello step: ->${EC2_HOST}<-"
          if [[ -z "$EC2_HOST" ]]; then
            echo "ERRORE: La variabile EC2_HOST è vuota!"
            exit 1
          fi
          mkdir -p ~/.ssh
          echo "Aggiungo host $EC2_HOST a known_hosts"
          ssh-keyscan -H "$EC2_HOST" >> ~/.ssh/known_hosts
          chmod 644 ~/.ssh/known_hosts

      - name: Deploy Script
        env:
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }}
          EC2_USER: ${{ env.EC2_USER }}
          EC2_HOST: ${{ env.EC2_HOST }}
        run: |
          set -e
          echo "Deploying module $MODULE_NAME, versione $VERSION to $EC2_HOST"

          if [ "$MODULE_NAME" = "distro" ]; then
             echo "[Deploy] Modulo distro: scarico gli artifact da S3 e li carico su EC2..."
             LOCAL_TARGET_PATH="/tmp/${MODULE_NAME}-${VERSION}/"
             S3_SOURCE_PATH="s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/"
             REMOTE_APP_PATH="/app/${MODULE_NAME}"
             REMOTE_ARTIFACT_PATH="${REMOTE_APP_PATH}/artifacts"

             mkdir -p "${LOCAL_TARGET_PATH}"

             echo "[Deploy] Tentativo di download da: ${S3_SOURCE_PATH} a ${LOCAL_TARGET_PATH}"
             aws s3 cp "${S3_SOURCE_PATH}" "${LOCAL_TARGET_PATH}" --recursive
             if [ $? -ne 0 ]; then echo "[Deploy] ERRORE: Download da S3 fallito."; exit 1; fi

             echo "[Deploy] Download da S3 completato. Verifico contenuto locale in ${LOCAL_TARGET_PATH}:"; ls -lR "${LOCAL_TARGET_PATH}"
             if [ -z "$(ls -A ${LOCAL_TARGET_PATH})" ]; then echo "[Deploy] ERRORE: La directory ${LOCAL_TARGET_PATH} è vuota."; exit 1; fi

             echo "[Deploy] Eseguo comandi remoti su ${EC2_USER}@${EC2_HOST}..."
             ssh ${EC2_USER}@${EC2_HOST} "
               set -e
               echo '[Deploy Remote] Pulisco i vecchi artifact...'
               sudo rm -rf ${REMOTE_ARTIFACT_PATH}/*
               echo '[Deploy Remote] Creo directory target (${REMOTE_ARTIFACT_PATH})...'
               sudo mkdir -p ${REMOTE_ARTIFACT_PATH}
               sudo chown -R ${EC2_USER}:${EC2_USER} ${REMOTE_APP_PATH}
             "
             echo "[Deploy] Copio i nuovi file da locale (${LOCAL_TARGET_PATH}) a EC2 (${REMOTE_ARTIFACT_PATH}/)..."
             scp -r ${LOCAL_TARGET_PATH}* ${EC2_USER}@${EC2_HOST}:${REMOTE_ARTIFACT_PATH}/

             echo "[Deploy] Verifico ZIP ed estraggo su EC2..."
             ssh ${EC2_USER}@${EC2_HOST} "
               set -e
               cd ${REMOTE_ARTIFACT_PATH}
               ZIP_FILE=\"${MODULE_NAME}-${VERSION}.zip\"
               if ls \$ZIP_FILE >/dev/null 2>&1; then
                 echo '[Deploy Remote] ZIP trovato. Estraggo...'
                 sudo apt-get update > /dev/null && sudo apt-get install -y unzip > /dev/null || echo 'unzip già installato o errore installazione'
                 unzip -o \$ZIP_FILE
                 if [ \$? -ne 0 ]; then # <-- Modifica per sintassi YAML
                   echo '[Deploy Remote] ERRORE: unzip fallito.'
                   exit 1
                 fi
                 echo '[Deploy Remote] Rinomino ZIP in ${MODULE_NAME}-last.zip'
                 mv \$ZIP_FILE ${MODULE_NAME}-last.zip
               else
                 echo '[Deploy Remote] ERRORE: File ZIP \$ZIP_FILE non trovato in ${REMOTE_ARTIFACT_PATH}.'; ls -la ${REMOTE_ARTIFACT_PATH}; exit 1;
               fi
               echo '[Deploy Remote] Imposto versione corrente come distro-last'
               echo 'distro-last' | sudo tee ${REMOTE_APP_PATH}/current-version.txt > /dev/null
             "
             echo "[Deploy] Deploy per distro completato."

          else
             echo "[Deploy] Modulo $MODULE_NAME (non-distro): uso deploy_module.sh."
             REMOTE_APP_PATH="/app/${MODULE_NAME}"
             REMOTE_DISTRO_SCRIPT_PATH="/app/distro/artifacts/aws/sit/script/deploy_module.sh"

             ssh ${EC2_USER}@${EC2_HOST} "
               set -e
               echo '[Deploy Remote] Assicuro esistenza directory ${REMOTE_APP_PATH}'
               sudo mkdir -p ${REMOTE_APP_PATH}
               sudo chown -R ${EC2_USER}:${EC2_USER} ${REMOTE_APP_PATH}

               if [ -f ${REMOTE_DISTRO_SCRIPT_PATH} ]; then
                 echo '[Deploy Remote] Trovato deploy_module.sh'
                 sudo chmod +x ${REMOTE_DISTRO_SCRIPT_PATH}
                 echo '[Deploy Remote] Eseguo: ${REMOTE_DISTRO_SCRIPT_PATH} ${MODULE_NAME} ${VERSION}'
                 ${REMOTE_DISTRO_SCRIPT_PATH} ${MODULE_NAME} ${VERSION}
               else
                 echo '[Deploy Remote] ERRORE: deploy_module.sh non trovato in ${REMOTE_DISTRO_SCRIPT_PATH}'; exit 1;
               fi
             "
             echo "[Deploy] Deploy per $MODULE_NAME completato."
          fi
          echo "Deployment completato per $MODULE_NAME."

      - name: Cleanup SSH Key File
        if: always()
        run: rm -f "${{ steps.fetch-secrets.outputs.SSH_KEY_PATH }}"

  slack_notification:
    name: Send Slack Notification
    runs-on: ubuntu-latest
    # Dipende solo dai job sempre eseguiti per evitare problemi con job skippati
    needs: [extract_module_info, build, test]
    if: always() # Esegui sempre, anche se i job precedenti falliscono
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      SSM_SLACK_WEBHOOK_PARAM: '/auxdromos/sit/global/slack_webhook_url' # Parametro SSM per il webhook Slack
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Fetch Slack Webhook URL from Parameter Store
        id: get-slack-webhook
        run: |
          SLACK_WEBHOOK=$(aws ssm get-parameter --name "${{ env.SSM_SLACK_WEBHOOK_PARAM }}" --with-decryption --query Parameter.Value --output text)
          if [[ -z "$SLACK_WEBHOOK" ]]; then 
            echo "AVVISO: Webhook Slack non configurato in Parameter Store"
            echo "SLACK_WEBHOOK_CONFIGURED=false" >> $GITHUB_OUTPUT
          else
            echo "::add-mask::$SLACK_WEBHOOK"
            echo "SLACK_WEBHOOK_URL=$SLACK_WEBHOOK" >> $GITHUB_ENV
            echo "SLACK_WEBHOOK_CONFIGURED=true" >> $GITHUB_OUTPUT
          fi

      - name: Prepare Slack Message
        id: slack-message
        if: steps.get-slack-webhook.outputs.SLACK_WEBHOOK_CONFIGURED == 'true'
        run: |
          # Analizza lo stato di ogni job specifico
          BUILD_RESULT="${{ needs.build.result }}"
          TEST_RESULT="${{ needs.test.result }}"
          
          # Job che si eseguono solo su main - recupera da needs solo se applicabile
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            # Recupera i risultati dai job condizionali tramite API GitHub se necessario
            UPLOAD_RESULT="$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs" | \
              jq -r '.jobs[] | select(.name | contains("Upload Artifacts to S3")) | .conclusion // "skipped"')"
            
            DEPLOY_RESULT="$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs" | \
              jq -r '.jobs[] | select(.name | contains("Deploy to SIT Environment")) | .conclusion // "skipped"')"
            
            DOCKER_RESULT="$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs" | \
              jq -r '.jobs[] | select(.name | contains("Build and Push Docker Image")) | .conclusion // "skipped"')"
          else
            UPLOAD_RESULT="not_applicable"
            DEPLOY_RESULT="not_applicable" 
            DOCKER_RESULT="not_applicable"
          fi
          
          # Determina lo stato complessivo
          FAILED_JOBS=""
          CANCELLED_JOBS=""
          
          # Controlla job essenziali (sempre eseguiti)
          if [[ "$BUILD_RESULT" == "failure" ]] || [[ "$TEST_RESULT" == "failure" ]]; then
            FAILED_JOBS="true"
          fi
          
          # Controlla job condizionali solo se dovevano essere eseguiti
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            if [[ "$UPLOAD_RESULT" == "failure" ]] || [[ "$DEPLOY_RESULT" == "failure" ]] || [[ "$DOCKER_RESULT" == "failure" ]]; then
              FAILED_JOBS="true"
            fi
            if [[ "$UPLOAD_RESULT" == "cancelled" ]] || [[ "$DEPLOY_RESULT" == "cancelled" ]] || [[ "$DOCKER_RESULT" == "cancelled" ]]; then
              CANCELLED_JOBS="true"
            fi
          fi
          
          if [[ "$BUILD_RESULT" == "cancelled" ]] || [[ "$TEST_RESULT" == "cancelled" ]]; then
            CANCELLED_JOBS="true"
          fi
          
          # Imposta stato finale
          if [[ "$FAILED_JOBS" == "true" ]]; then
            echo "status=:x: Fallito" >> $GITHUB_OUTPUT
            echo "color=danger" >> $GITHUB_OUTPUT
          elif [[ "$CANCELLED_JOBS" == "true" ]]; then
            echo "status=:warning: Annullato" >> $GITHUB_OUTPUT
            echo "color=warning" >> $GITHUB_OUTPUT
          else
            echo "status=:white_check_mark: Successo" >> $GITHUB_OUTPUT
            echo "color=good" >> $GITHUB_OUTPUT
          fi
          
          # Prepara messaggi di stato per ogni job
          echo "build_status=Build: $BUILD_RESULT" >> $GITHUB_OUTPUT
          echo "test_status=Test: $TEST_RESULT" >> $GITHUB_OUTPUT
          
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            echo "deploy_status=Deploy SIT: $DEPLOY_RESULT" >> $GITHUB_OUTPUT
            echo "docker_status=Docker Build: $DOCKER_RESULT" >> $GITHUB_OUTPUT
            echo "upload_status=Upload S3: $UPLOAD_RESULT" >> $GITHUB_OUTPUT
            echo "environment_info=Ambiente: Produzione (SIT)" >> $GITHUB_OUTPUT
          else
            echo "deploy_status=Deploy SIT: non applicabile (branch: ${{ github.ref_name }})" >> $GITHUB_OUTPUT
            echo "docker_status=Docker Build: non applicabile (branch: ${{ github.ref_name }})" >> $GITHUB_OUTPUT
            echo "upload_status=Upload S3: non applicabile (branch: ${{ github.ref_name }})" >> $GITHUB_OUTPUT
            echo "environment_info=Ambiente: Sviluppo (branch: ${{ github.ref_name }})" >> $GITHUB_OUTPUT
          fi

      - name: Send Slack Notification
        if: steps.get-slack-webhook.outputs.SLACK_WEBHOOK_CONFIGURED == 'true'
        uses: slackapi/slack-github-action@v1.25.0
        with:
          payload: |
            {
              "attachments": [
                {
                  "color": "${{ steps.slack-message.outputs.color }}",
                  "blocks": [
                    {
                      "type": "header",
                      "text": {
                        "type": "plain_text",
                        "text": "${{ steps.slack-message.outputs.status }} - ${{ env.MODULE_NAME }} v${{ env.VERSION }}"
                      }
                    },
                    {
                      "type": "section",
                      "fields": [
                        {
                          "type": "mrkdwn",
                          "text": "*Repository:*\n${{ github.repository }}"
                        },
                        {
                          "type": "mrkdwn",
                          "text": "*Branch:*\n${{ github.ref_name }}"
                        },
                        {
                          "type": "mrkdwn",
                          "text": "*Trigger:*\n${{ github.event_name }}"
                        },
                        {
                          "type": "mrkdwn",
                          "text": "*${{ steps.slack-message.outputs.environment_info }}*"
                        }
                      ]
                    },
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "*Stato Job:*\n${{ steps.slack-message.outputs.build_status }}\n${{ steps.slack-message.outputs.test_status }}\n${{ steps.slack-message.outputs.upload_status }}\n${{ steps.slack-message.outputs.deploy_status }}\n${{ steps.slack-message.outputs.docker_status }}"
                      }
                    },
                    {
                      "type": "actions",
                      "elements": [
                        {
                          "type": "button",
                          "text": {
                            "type": "plain_text",
                            "text": "Visualizza Workflow"
                          },
                          "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                        }
                      ]
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ env.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

  cleanup_artifacts:
    name: Cleanup Old Artifacts
    runs-on: ubuntu-latest
    needs: [slack_notification]
    if: always() # Esegui sempre, anche se i job precedenti falliscono
    permissions:
      actions: write # Necessario per eliminare gli artifact
    # Questo job automatizza la rimozione degli artifact più vecchi di un certo numero di giorni
    # La soglia di età può essere configurata tramite il parametro 'artifact-retention-days'
    steps:
      - name: Cleanup Old Artifacts
        run: |
          echo "=== Inizia la pulizia degli artifact più vecchi ==="

          # Imposta la soglia di età in giorni (gli artifact più vecchi di questa soglia verranno eliminati)
          DAYS_OLD=${{ inputs.artifact-retention-days }}
          echo "Soglia di età impostata a $DAYS_OLD giorni"

          # Ottieni il token GitHub per l'API
          TOKEN="${{ secrets.GITHUB_PACKAGES_TOKEN }}"

          # Ottieni l'ID del repository
          REPO_ID=$(curl -s -H "Authorization: token $TOKEN" \
            "https://api.github.com/repos/${{ github.repository }}" | \
            jq -r '.id')

          echo "Repository ID: $REPO_ID"
          echo "Repository: ${{ github.repository }}"

          # Calcola la data limite (oggi - DAYS_OLD)
          # Usa una soluzione più portabile per calcolare la data limite
          CURRENT_DATE=$(date +%s)
          SECONDS_IN_DAY=86400
          CUTOFF_DATE=$((CURRENT_DATE - (DAYS_OLD * SECONDS_IN_DAY)))
          # Usa date con formato compatibile con Ubuntu
          CUTOFF_DATE_HUMAN=$(date -u --date="@$CUTOFF_DATE" "+%Y-%m-%d")
          echo "Data limite: $CUTOFF_DATE_HUMAN (timestamp: $CUTOFF_DATE)"

          echo "Recupero lista degli artifact dal repository..."
          # Ottieni la lista degli artifact
          ARTIFACTS=$(curl -s -H "Authorization: token $TOKEN" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts?per_page=100")

          TOTAL_ARTIFACTS=$(echo "$ARTIFACTS" | jq -r '.total_count')
          echo "Totale artifact trovati: $TOTAL_ARTIFACTS"

          echo "Identificazione degli artifact più vecchi della soglia..."
          # Estrai gli ID degli artifact più vecchi della soglia
          # Usa strptime per convertire la data ISO 8601 in timestamp Unix
          OLD_ARTIFACT_IDS=$(echo "$ARTIFACTS" | jq -r ".artifacts[] | 
            select((.created_at | strptime(\"%Y-%m-%dT%H:%M:%SZ\") | mktime) < $CUTOFF_DATE) | 
            .id")

          # Conta quanti artifact verranno eliminati
          COUNT=$(echo "$OLD_ARTIFACT_IDS" | grep -v '^$' | wc -l)
          echo "Trovati $COUNT artifact più vecchi di $DAYS_OLD giorni da eliminare"

          if [ "$COUNT" -eq 0 ]; then
            echo "Nessun artifact da eliminare. Operazione completata."
            exit 0
          fi

          echo "=== Inizio eliminazione degli artifact ==="
          # Elimina gli artifact più vecchi
          SUCCESS_COUNT=0
          FAIL_COUNT=0

          for ARTIFACT_ID in $OLD_ARTIFACT_IDS; do
            echo "Eliminazione artifact ID: $ARTIFACT_ID"
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -X DELETE -H "Authorization: token $TOKEN" \
              "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID")

            if [ "$HTTP_CODE" -eq 204 ] || [ "$HTTP_CODE" -eq 200 ]; then
              echo "✓ Artifact $ARTIFACT_ID eliminato con successo (HTTP $HTTP_CODE)"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
            else
              echo "✗ Errore nell'eliminazione dell'artifact $ARTIFACT_ID (HTTP $HTTP_CODE)"
              FAIL_COUNT=$((FAIL_COUNT + 1))
            fi
          done

          echo "=== Riepilogo pulizia artifact ==="
          echo "Artifact elaborati: $COUNT"
          echo "Eliminati con successo: $SUCCESS_COUNT"
          echo "Errori: $FAIL_COUNT"
          echo "=== Pulizia degli artifact completata ==="
