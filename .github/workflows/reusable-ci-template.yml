# .github/workflows/reusable-ci-template.yml
# Workflow riutilizzabile per build, test, package, deploy di moduli AuxDromos
name: Reusable AuxDromos CI/CD

on:
  workflow_call:
    # Definisci gli input che il workflow chiamante può passare
    inputs:
      java-version:
        description: 'Versione JDK da usare'
        required: false
        type: string
        default: '17'
      # Potresti aggiungere input per i percorsi dei parametri SSM se vuoi renderli configurabili
      # ssm-param-path-prefix:
      #   description: 'Prefisso per i parametri SSM (es. /github/sit/)'
      #   required: false
      #   type: string
      #   default: '/github/sit/' # O un default sensato

    # Non sono più richiesti segreti AWS/EC2 dal chiamante
    secrets: {} # Rimuovi tutti i segreti precedenti

# Imposta la regione AWS staticamente
# Rimuovi le altre variabili globali che verranno recuperate da SSM
env:
  AWS_REGION: us-east-1 # <-- IMPOSTA QUI LA TUA REGIONE STATICA

jobs:
  extract_module_info:
    name: Prepare - Extract Module Info
    runs-on: ubuntu-latest
    outputs:
      module_name: ${{ steps.extract.outputs.MODULE_NAME }}
      version: ${{ steps.extract.outputs.VERSION }}
    steps:
      # Questo checkout prende il codice del REPOSITORY CHIAMANTE
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Extract Info from pom.xml
        id: extract
        run: |
          echo "Estrazione delle informazioni dal pom.xml del repository chiamante..."
          # --- USA UN METODO PIU' ROBUSTO PER ESTRARRE DA POM ---
          if [ -f "pom.xml" ]; then
            echo "Installazione Maven per estrazione..."
            # Assicurati che Java sia disponibile se non giget update && sudo apt-get install -y openjdk-17-jdk maven
            # Oppure usa setup-java action se preferisci
            echo "Usando Maven per estrarre artifactId e version..."
            MODULE_NAME=$(mvn help:evaluate -Dexpression=project.artifactId -q -DforceStdout)
            VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)
          else
            echo "ATTENZIONE: pom.xml non trovato nel repository chiamante."
            MODULE_NAME=${{ github.repository_owner }}-${{ github.repository }} # Nome repo come fallback
            MODULE_NAME=$(basename $MODULE_NAME) # Prendi solo il nome del repo
            SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)
            VERSION="1.0.0-${SHORT_SHA}" # Versione di fallback
          fi

          if [[ -z "$MODULE_NAME" ]] || [[ -z "$VERSION" ]]; then
             echo "ERRORE: Impossibile estrarre MODULE_NAME o VERSION."
             exit 1
          fi

          echo "Modulo $MODULE_NAME, Versione $VERSION"
          echo "MODULE_NAME=$MODULE_NAME" >> $GITHUB_OUTPUT
          echo "VERSION=$VERSION" >> $GITHUB_OUTPUT

  check_version:
    name: Check Version Existence (Main Branch Only)
    runs-on: ubuntu-latest
    needs: extract_module_info
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      # Definisci qui il nome del parametro SSM per l'Account ID se serve
      # SSM_AWS_ACCOUNT_ID_PARAM: '/github/common/aws_account_id' # Esempio

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }} # Usa la regione statica

      # --- Opzionale: Recupera Account ID se serve per ECR o altro ---
      # - name: Fetch AWS Account ID from Parameter Store
      #   id: get-aws-account
      #   run: |
      #     AWS_ACCOUNT_ID_VAL=$(aws ssm get-parameter --name "${{ env.SSM_AWS_ACCOUNT_ID_PARAM }}" --query Parameter.Value --output text)
      #     echo "AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID_VAL" >> $GITHUB_ENV

      - name: Run Version Check Script
        # env:
        #   AWS_ACCOUNT_ID: ${{ steps.get-aws-account.outputs.AWS_ACCOUNT_ID }} # Se recuperato sopra
        run: |
          set -e
          set -o pipefail
          echo "Verifica della versione per il branch 'main'..."

          if [[ -z "$MODULE_NAME" ]] || [[ -z "$VERSION" ]]; then
            echo "ERRORE: MODULE_NAME ('$MODULE_NAME') o VERSION ('$VERSION') sono vuote."
            exit 1
          fi

          if [[ "$VERSION" == *"SNAPSHOT"* ]]; then
            echo "Errore: Versione '$VERSION' non valida in 'main' (SNAPSHOT non consentito)."
            exit 1
          fi

          ECR_REPO_NAME="auxdromos-$MODULE_NAME"
          echo "Controllo ECR per repository $ECR_REPO_NAME e tag $VERSION..."
          if aws ecr describe-images --repository-name "$ECR_REPO_NAME" --image-ids imageTag="$VERSION" --region "$AWS_REGION" > /dev/null 2>&1; then
            echo "Errore: La versione '$VERSION' è già presente su ECR per il modulo '$MODULE_NAME'."
            exit 1
          else
              if ! aws ecr describe-repositories --repository-names "$ECR_REPO_NAME" --region "$AWS_REGION" > /dev/null 2>&1; then
                  echo "Nota: Repository ECR '$ECR_REPO_NAME' non esiste ancora (verrà creato nel job docker)."
              fi
              echo "Versione '$VERSION' valida per main. Procedo..."
          fi

  build:
    name: Build Project
    runs-on: ubuntu-latest
    needs: [extract_module_info, check_version]
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java-version }}
          distribution: 'corretto'
          cache: 'maven'

      - name: Build with Maven
        run: |
          echo "Build del modulo $MODULE_NAME versione $VERSION..."
          mvn clean package -Psit -DskipTests

      - name: Create Build Info
        run: |
          mkdir -p target
          cat > target/build-info.json <<EOF
          {
            "moduleName": "$MODULE_NAME",
            "version": "$VERSION",
            "buildDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "branch": "${{ github.ref_name }}",
            "commitHash": "${{ github.sha }}"
          }
          EOF
          echo "Contenuto build-info.json:"
          cat target/build-info.json

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: |
            target/*.jar
            target/distribution/
            target/build-info.json
          if-no-files-found: error

  test:
    name: Test Project
    runs-on: ubuntu-latest
    needs: [extract_module_info, build]
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: ${{ inputs.java-version }}
          distribution: 'corretto'
          cache: 'maven'

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/build

      - name: Run Tests with Maven
        run: |
          echo "Test del modulo $MODULE_NAME versione $VERSION..."
          mvn test

  package_configs:
    name: Package Configuration Files (Main Branch Only)
    runs-on: ubuntu-latest
    needs: extract_module_info
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Install zip
        run: sudo apt-get update && sudo apt-get install -y zip

      - name: Create Config Package
        run: |
          set -x
          echo "Creazione pacchetto di configurazione $MODULE_NAME versione $VERSION..."
          mkdir -p dist
          FILES_TO_ZIP=""
          for DIR in aws docker scripts env; do
            if [ -d "$DIR" ]; then
              FILES_TO_ZIP="$FILES_TO_ZIP $DIR/"
              echo "Aggiungo directory $DIR al ZIP"
            fi
          done
          find . -maxdepth 1 \( -name '*.yml' -o -name '*.yaml' -o -name '*.properties' \) -print0 | while IFS= read -r -d $'\0' file; do
              if [ -f "$file" ]; then
                  BASENAME=$(basename "$file")
                  FILES_TO_ZIP="$FILES_TO_ZIP $BASENAME"
                  echo "Aggiungo file $BASENAME al ZIP"
              fi
          done

          if [ -n "$FILES_TO_ZIP" ]; then
            echo "Creazione ZIP con: $FILES_TO_ZIP"
            zip -r "dist/$MODULE_NAME-$VERSION.zip" $FILES_TO_ZIP
          else
            echo "AVVISO: Nessun file/directory di configurazione standard trovato da includere nel ZIP, genero ZIP vuoto"
            touch empty.txt
            zip -r "dist/$MODULE_NAME-$VERSION.zip" empty.txt
            rm empty.txt
          fi
          if [ -f "dist/$MODULE_NAME-$VERSION.zip" ]; then echo "File ZIP creato dist/$MODULE_NAME-$VERSION.zip"; else echo "ERRORE Il file ZIP non è stato creato"; exit 1; fi

          echo "{\"moduleName\":\"$MODULE_NAME\",\"version\":\"$VERSION\",\"buildDate\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"branch\":\"${{ github.ref_name }}\",\"commitHash\":\"${{ github.sha }}\"}" > dist/manifest.json

      - name: Upload config package artifact
        uses: actions/upload-artifact@v4
        with:
          name: config-package-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: dist/
          if-no-files-found: error

  build_docker:
    name: Build and Push Docker Image (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, build]
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      ECR_REPOSITORY: auxdromos-${{ needs.extract_module_info.outputs.module_name }}
      # Definisci qui il nome del parametro SSM per l'Account ID se serve
      # SSM_AWS_ACCOUNT_ID_PARAM: '/github/common/aws_account_id' # Esempio
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout calling repository code
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/build

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }} # Usa la regione statica

      # --- Opzionale: Recupera Account ID se serve per ECR o altro ---
      # - name: Fetch AWS Account ID from Parameter Store
      #   id: get-aws-account
      #   run: |
      #     AWS_ACCOUNT_ID_VAL=$(aws ssm get-parameter --name "${{ env.SSM_AWS_ACCOUNT_ID_PARAM }}" --query Parameter.Value --output text)
      #     echo "AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID_VAL" >> $GITHUB_ENV

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Check for Dockerfile and Build/Push
        id: docker_build
        # env:
        #   AWS_ACCOUNT_ID: ${{ steps.get-aws-account.outputs.AWS_ACCOUNT_ID }} # Se recuperato sopra
        run: |
          if [ -f "Dockerfile" ]; then
            echo "Dockerfile trovato per $MODULE_NAME, procedo con build e push"

            aws ecr describe-repositories --repository-names "${ECR_REPOSITORY}" --region "${AWS_REGION}" > /dev/null 2>&1 || \
              (echo "Repository ECR '${ECR_REPOSITORY}' non esiste, lo creo..." && \
               aws ecr create-repository --repository-name "${ECR_REPOSITORY}" --region "${AWS_REGION}" && \
               echo "Repository ECR creato con successo.") || \
              (echo "Repository ECR '${ECR_REPOSITORY}' esiste già.")

            ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}
            IMAGE_TAG="${ECR_REGISTRY}/${ECR_REPOSITORY}:${VERSION}"

            echo "Building image: ${IMAGE_TAG}"
            DOCKER_BUILD_ARGS=""
            # Potresti recuperare BUILD_ARGS da SSM se necessario
            # BUILD_ARGS_VAL=$(aws ssm get-parameter --name "/github/common/docker_build_args" --query Parameter.Value --output text)
            # if [ -n "$BUILD_ARGS_VAL" ]; then DOCKER_BUILD_ARGS="$BUILD_ARGS_VAL"; fi

            docker buildx build --push \
              $DOCKER_BUILD_ARGS \
              -t "${IMAGE_TAG}" \
              --platform linux/amd64 .

            echo "Immagine Docker caricata con successo: ${IMAGE_TAG}"
            echo "docker_image_pushed=true" >> $GITHUB_OUTPUT
          else
            echo "Dockerfile non trovato per $MODULE_NAME nel repository chiamante, salto build e push Docker"
            echo "docker_image_pushed=false" >> $GITHUB_OUTPUT
          fi

  upload_to_s3:
    name: Upload Artifacts to S3
    runs-on: ubuntu-latest
    needs: [extract_module_info, build, package_configs]
    if: github.ref_name == 'main' && github.event_name == 'push'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      # Definisci qui il nome del parametro SSM per il bucket S3
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name' # Esempio

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/build

      - name: Download config package artifact
        uses: actions/download-artifact@v4
        with:
          name: config-package-${{ needs.extract_module_info.outputs.module_name }}-${{ needs.extract_module_info.outputs.version }}-${{ github.run_id }}
          path: artifacts/package

      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }} # Usa la regione statica

      - name: Fetch S3 Bucket Name from Parameter Store
        id: get-s3-bucket
        run: |
          S3_BUCKET=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)
          echo "S3_BUCKET_NAME=$S3_BUCKET" >> $GITHUB_ENV # Imposta per i prossimi step di questo job

      - name: Upload to S3
        env:
          # Rende S3_BUCKET_NAME disponibile allo script
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }} # Impostata dallo step precedente
        run: |
          set -e
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            S3_PATH="${MODULE_NAME}/${VERSION}/"
          else
            echo "ERRORE: Upload S3 configurato solo per il branch 'main'."
            exit 1
          fi

          S3_URI="s3://${S3_BUCKET_NAME}/${S3_PATH}" # Usa la variabile d'ambiente
          echo "Uploading artifacts for $MODULE_NAME version $VERSION into ${S3_URI}"

          JAR_COUNT=$(find artifacts/build -maxdepth 1 -name '*.jar' | wc -l)
          if [ "$JAR_COUNT" -gt 0 ]; then
            echo "Uploading JAR files..."
            aws s3 cp artifacts/build/ "${S3_URI}" --recursive --exclude "*" --include "*.jar"
          else
            echo "Nessun file JAR trovato in artifacts/build/"
          fi

          if [ -d "artifacts/build/distribution/" ]; then
            echo "Uploading distribution files..."
            aws s3 cp artifacts/build/distribution/ "${S3_URI}distribution/" --recursive
          fi

          if [ -f "artifacts/build/build-info.json" ]; then
            echo "Uploading build-info..."
            aws s3 cp artifacts/build/build-info.json "${S3_URI}build-info.json"
          fi

          ZIP_FILE="artifacts/package/$MODULE_NAME-$VERSION.zip"
          if [ -f "$ZIP_FILE" ]; then
            echo "Uploading ZIP file $ZIP_FILE..."
            aws s3 cp "$ZIP_FILE" "${S3_URI}$MODULE_NAME-$VERSION.zip"
          else
            echo "ERRORE: Il file ZIP $ZIP_FILE non esiste. Correggi il job package_configs."
            exit 1
          fi

          echo "Verifica upload:"
          aws s3 ls "${S3_URI}" --recursive

  tag_latest:
    name: Tag Latest Version in S3 (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, upload_to_s3]
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      # Definisci qui il nome del parametro SSM per il bucket S3
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name' # Esempio

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }} # Usa la regione statica

      - name: Fetch S3 Bucket Name from Parameter Store
        id: get-s3-bucket
        run: |
          S3_BUCKET=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)
          echo "S3_BUCKET_NAME=$S3_BUCKET" >> $GITHUB_ENV

      - name: Create and Upload latest.json
        env:
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }} # Impostata dallo step precedente
        run: |
          set -e
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            LATEST_PATH="${MODULE_NAME}/latest.json"
            S3_BASE_PATH="${MODULE_NAME}/"
          else
            echo "ERRORE: Tag Latest configurato solo per il branch 'main'."
            exit 1
          fi

          S3_URI="s3://${S3_BUCKET_NAME}/${LATEST_PATH}" # Usa la variabile d'ambiente

          cat > latest.json <<EOF
          {
            "moduleName": "$MODULE_NAME",
            "latestVersion": "$VERSION",
            "updateDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "branch": "${{ github.ref_name }}",
            "commitHash": "${{ github.sha }}"
          }
          EOF

          echo "Tagging della versione $VERSION come 'latest' per $MODULE_NAME nel path $S3_BASE_PATH"
          aws s3 cp latest.json "${S3_URI}"
          echo "Contenuto di latest.json caricato:"
          cat latest.json

  cleanup_s3:
    name: Cleanup Old S3 Versions (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, tag_latest]
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      # Definisci qui il nome del parametro SSM per il bucket S3
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name' # Esempio

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }} # Usa la regione statica

      - name: Fetch S3 Bucket Name from Parameter Store
        id: get-s3-bucket
        run: |
          S3_BUCKET=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)
          echo "S3_BUCKET_NAME=$S3_BUCKET" >> $GITHUB_ENV

      - name: Run S3 Cleanup Script
        env:
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }} # Impostata dallo step precedente
        run: |
          set -e
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            S3_BASE_PATH="${MODULE_NAME}/"
          else
            echo "ERRORE: Cleanup S3 configurato solo per il branch 'main'."
            exit 1
          fi

          S3_URI_BASE="s3://${S3_BUCKET_NAME}/${S3_BASE_PATH}" # Usa la variabile d'ambiente
          KEEP_LATEST=5

          echo "Pulizia S3 per $S3_BASE_PATH, mantenendo solo le ultime $KEEP_LATEST versioni..."
          echo "Elenco contenuti in ${S3_URI_BASE}"

          RAW_PREFIXES=$(aws s3api list-objects-v2 --bucket "${S3_BUCKET_NAME}" --prefix "${S3_BASE_PATH}" --delimiter '/' --query 'CommonPrefixes[].Prefix' --output text)
          echo "Prefissi grezzi trovati: $RAW_PREFIXES"

          VERSIONS=$(echo "$RAW_PREFIXES" | tr '\t' '\n' | sed "s#^${S3_BASE_PATH}##" | sed 's#/$##')
          echo "Versioni trovate (candidate): $VERSIONS"

          VALID_VERSIONS=""
          VERSION_COUNT=0
          if [[ -n "$VERSIONS" ]]; then
            VALID_VERSIONS=$(echo "$VERSIONS" | grep -E '^[0-9]+\.[0-9]+(\.[0-9]+)?(-[a-zA-Z0-9.-]+)?$' | grep -v '^latest$' || true)
            VERSION_COUNT=$(echo "$VALID_VERSIONS" | grep -cv '^$' || true)
          fi
          echo "Versioni valide filtrate: $VALID_VERSIONS"
          echo "Numero di versioni valide: $VERSION_COUNT"

          if [[ $VERSION_COUNT -gt $KEEP_LATEST ]]; then
            TO_DELETE=$(($VERSION_COUNT - $KEEP_LATEST))
            echo "Rimozione delle $TO_DELETE versioni più vecchie..."
            VERSIONS_TO_DELETE=$(echo "$VALID_VERSIONS" | sort -V | head -n $TO_DELETE)
            echo "Versioni da eliminare: $VERSIONS_TO_DELETE"
            for OLD_VERSION in $VERSIONS_TO_DELETE; do
              if [[ -n "$OLD_VERSION" ]]; then
                echo "Rimozione versione $OLD_VERSION da S3 (${S3_URI_BASE}${OLD_VERSION}/)..."
                aws s3 rm "${S3_URI_BASE}${OLD_VERSION}/" --recursive
              fi
            done
          else
            echo "Ci sono $VERSION_COUNT versioni valide, non è necessaria alcuna pulizia (< $((KEEP_LATEST + 1)))."
          fi

  deploy_sit:
    name: Deploy to SIT Environment (Main Branch Only)
    runs-on: ubuntu-latest
    needs: [extract_module_info, upload_to_s3, build_docker]
    if: github.event_name == 'push' && github.ref_name == 'main'
    env:
      MODULE_NAME: ${{ needs.extract_module_info.outputs.module_name }}
      VERSION: ${{ needs.extract_module_info.outputs.version }}
      # Definisci i nomi dei parametri SSM per EC2 e S3
      SSM_EC2_USER_PARAM: '/github/sit/ec2_user' # Esempio
      SSM_EC2_HOST_PARAM: '/github/sit/ec2_host' # Esempio
      SSM_EC2_KEY_PARAM: '/github/sit/ec2_private_key' # Esempio (SecureString)
      SSM_S3_BUCKET_PARAM: '/github/common/s3_bucket_name' # Esempio (se serve per distro)

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::463470955561:role/GitHubActions-AuxDromos-DeployRole
          aws-region: ${{ env.AWS_REGION }} # Usa la regione statica

      - name: Fetch EC2 Details and S3 Bucket from Parameter Store
        id: fetch-secrets
        run: |
          EC2_USER_VAL=$(aws ssm get-parameter --name "${{ env.SSM_EC2_USER_PARAM }}" --query Parameter.Value --output text)
          EC2_HOST_VAL=$(aws ssm get-parameter --name "${{ env.SSM_EC2_HOST_PARAM }}" --query Parameter.Value --output text)
          EC2_KEY_VAL=$(aws ssm get-parameter --name "${{ env.SSM_EC2_KEY_PARAM }}" --with-decryption --query Parameter.Value --output text)
          S3_BUCKET_VAL=$(aws ssm get-parameter --name "${{ env.SSM_S3_BUCKET_PARAM }}" --query Parameter.Value --output text)

          echo "EC2_USER=$EC2_USER_VAL" >> $GITHUB_ENV
          echo "EC2_HOST=$EC2_HOST_VAL" >> $GITHUB_ENV
          echo "S3_BUCKET_NAME=$S3_BUCKET_VAL" >> $GITHUB_ENV # Imposta anche se usato solo da distro

          # Salva la chiave SSH in un file temporaneo
          SSH_KEY_PATH=$(mktemp)
          echo "$EC2_KEY_VAL" > "$SSH_KEY_PATH"
          chmod 600 "$SSH_KEY_PATH"
          echo "::add-mask::$EC2_KEY_VAL" # Maschera il valore della chiave nei log

          # Rendi disponibile il path del file per il prossimo step
          echo "SSH_KEY_PATH=$SSH_KEY_PATH" >> $GITHUB_OUTPUT

      - name: Setup SSH Agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          # Usa il path del file temporaneo contenente la chiave
          ssh-private-key: ${{ steps.fetch-secrets.outputs.SSH_KEY_PATH }}

      - name: Add EC2 Host to Known Hosts
        env:
          EC2_HOST: ${{ env.EC2_HOST }} # Impostata da fetch-secrets
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H $EC2_HOST >> ~/.ssh/known_hosts # Usa la variabile d'ambiente
          chmod 644 ~/.ssh/known_hosts

      - name: Deploy Script
        env:
          # Rendi disponibili le variabili recuperate allo script
          S3_BUCKET_NAME: ${{ env.S3_BUCKET_NAME }}
          EC2_USER: ${{ env.EC2_USER }}
          EC2_HOST: ${{ env.EC2_HOST }}
        run: |
          set -e
          echo "Deploying module $MODULE_NAME, versione $VERSION to $EC2_HOST"

          if [ "$MODULE_NAME" = "distro" ]; then
             echo "[Deploy] Modulo distro: scarico gli artifact da S3 e li carico su EC2..."
             LOCAL_TARGET_PATH="/tmp/${MODULE_NAME}-${VERSION}/"
             S3_SOURCE_PATH="s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/" # Usa S3_BUCKET_NAME da env
             REMOTE_APP_PATH="/app/${MODULE_NAME}"
             REMOTE_ARTIFACT_PATH="${REMOTE_APP_PATH}/artifacts"

             mkdir -p "${LOCAL_TARGET_PATH}"

             echo "[Deploy] Tentativo di download da: ${S3_SOURCE_PATH} a ${LOCAL_TARGET_PATH}"
             aws s3 cp "${S3_SOURCE_PATH}" "${LOCAL_TARGET_PATH}" --recursive
             if [ $? -ne 0 ]; then echo "[Deploy] ERRORE: Download da S3 fallito."; exit 1; fi

             echo "[Deploy] Download da S3 completato. Verifico contenuto locale in ${LOCAL_TARGET_PATH}:"; ls -lR "${LOCAL_TARGET_PATH}"
             if [ -z "$(ls -A ${LOCAL_TARGET_PATH})" ]; then echo "[Deploy] ERRORE: La directory ${LOCAL_TARGET_PATH} è vuota."; exit 1; fi

             echo "[Deploy] Eseguo comandi remoti su ${EC2_USER}@${EC2_HOST}..." # Usa EC2_USER/HOST da env
             ssh ${EC2_USER}@${EC2_HOST} "
               set -e
               echo '[Deploy Remote] Pulisco i vecchi artifact...'
               sudo rm -rf ${REMOTE_ARTIFACT_PATH}/*
               echo '[Deploy Remote] Creo directory target (${REMOTE_ARTIFACT_PATH})...'
               sudo mkdir -p ${REMOTE_ARTIFACT_PATH}
               sudo chown -R ${EC2_USER}:${EC2_USER} ${REMOTE_APP_PATH}
             "
             echo "[Deploy] Copio i nuovi file da locale (${LOCAL_TARGET_PATH}) a EC2 (${REMOTE_ARTIFACT_PATH}/)..."
             scp -r ${LOCAL_TARGET_PATH}* ${EC2_USER}@${EC2_HOST}:${REMOTE_ARTIFACT_PATH}/

             echo "[Deploy] Verifico ZIP ed estraggo su EC2..."
             ssh ${EC2_USER}@${EC2_HOST} "
               set -e
               cd ${REMOTE_ARTIFACT_PATH}
               ZIP_FILE=\"${MODULE_NAME}-${VERSION}.zip\"
               if ls \$ZIP_FILE >/dev/null 2>&1; then
                 echo '[Deploy Remote] ZIP trovato. Estraggo...'
                 # Assicurati che unzip sia installato
                 sudo apt-get update > /dev/null && sudo apt-get install -y unzip > /dev/null || echo 'unzip già installato o errore installazione'
                 unzip -o \$ZIP_FILE || { echo '[Deploy Remote] ERRORE: unzip fallito.'; exit 1; }
                 echo '[Deploy Remote] Rinomino ZIP in ${MODULE_NAME}-last.zip'
                 mv \$ZIP_FILE ${MODULE_NAME}-last.zip
               else
                 echo '[Deploy Remote] ERRORE: File ZIP \$ZIP_FILE non trovato in ${REMOTE_ARTIFACT_PATH}.'; ls -la ${REMOTE_ARTIFACT_PATH}; exit 1;
               fi
               echo '[Deploy Remote] Imposto versione corrente come distro-last'
               echo 'distro-last' | sudo tee ${REMOTE_APP_PATH}/current-version.txt > /dev/null
             "
             echo "[Deploy] Deploy per distro completato."

          else
             echo "[Deploy] Modulo $MODULE_NAME (non-distro): uso deploy_module.sh."
             REMOTE_APP_PATH="/app/${MODULE_NAME}"
             REMOTE_DISTRO_SCRIPT_PATH="/app/distro/artifacts/aws/sit/script/deploy_module.sh"

             ssh ${EC2_USER}@${EC2_HOST} " # Usa EC2_USER/HOST da env
               set -e
               echo '[Deploy Remote] Assicuro esistenza directory ${REMOTE_APP_PATH}'
               sudo mkdir -p ${REMOTE_APP_PATH}
               sudo chown -R ${EC2_USER}:${EC2_USER} ${REMOTE_APP_PATH}

               if [ -f ${REMOTE_DISTRO_SCRIPT_PATH} ]; then
                 echo '[Deploy Remote] Trovato deploy_module.sh'
                 sudo chmod +x ${REMOTE_DISTRO_SCRIPT_PATH}
                 echo '[Deploy Remote] Eseguo: ${REMOTE_DISTRO_SCRIPT_PATH} ${MODULE_NAME} ${VERSION}'
                 ${REMOTE_DISTRO_SCRIPT_PATH} ${MODULE_NAME} ${VERSION}
               else
                 echo '[Deploy Remote] ERRORE: deploy_module.sh non trovato in ${REMOTE_DISTRO_SCRIPT_PATH}'; exit 1;
               fi
             "
             echo "[Deploy] Deploy per $MODULE_NAME completato."
          fi
          echo "Deployment completato per $MODULE_NAME."

      # --- STEP DI PULIZIA CHIAVE SSH ---
      - name: Cleanup SSH Key File
        if: always() # Esegui sempre, anche se il deploy fallisce
        run: rm -f "${{ steps.fetch-secrets.outputs.SSH_KEY_PATH }}"
