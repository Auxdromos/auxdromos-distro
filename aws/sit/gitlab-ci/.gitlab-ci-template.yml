image: maven:3.9.9-amazoncorretto-17

stages:
  - prepare
  - check_version
  - build
  - test
  - artifact_upload_s3
  - build_docker
  - deploy_sit

# Rimuovo l'inclusione duplicata del template di security

extract_module_name:
  stage: prepare
  script: |
    echo "Estrazione del MODULE_NAME dal pom.xml..."
    export MODULE_NAME=$(grep "<artifactId>" pom.xml | head -1 | sed 's/[<>]/|/g' | cut -d'|' -f3)
    if [ -z "$MODULE_NAME" ]; then 
      echo "Errore: impossibile estrarre MODULE_NAME dal pom.xml"
      exit 1
    fi
    echo "MODULE_NAME estratto: $MODULE_NAME"
    echo "MODULE_NAME=$MODULE_NAME" >> module_name.env
    
    # Estrai anche la versione
    export VERSION=$(grep "<version>" pom.xml | head -1 | sed 's/[<>]/|/g' | cut -d'|' -f3)
    echo "VERSION=$VERSION" >> module_name.env
    echo "VERSION estratta: $VERSION"
    
    # Aggiungi informazioni sul branch
    echo "CI_COMMIT_REF_NAME=$CI_COMMIT_REF_NAME" >> module_name.env
  artifacts:
    reports:
      dotenv: module_name.env

check_version:
  stage: check_version
  dependencies:
    - extract_module_name
  image:
    name: amazon/aws-cli:latest
    entrypoint: [""]
  script: |
    set -e
    set -o pipefail

    echo "Verifica della versione..."

    # Carichiamo VERSION dal file .env creato prima
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Regole diverse per branch diversi
    if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      # Solo per main: vietiamo l'uso di SNAPSHOT
      if [[ "$VERSION" == *"SNAPSHOT"* ]]; then
        echo "Errore: Versione '$VERSION' non valida in 'main' (SNAPSHOT non consentito)."
        exit 1
      fi
    
      # Solo per main: verifichiamo su ECR
      if aws ecr describe-images --repository-name auxdromos-$MODULE_NAME --image-ids imageTag=$VERSION --region $AWS_DEFAULT_REGION > /dev/null 2>&1; then
        echo "Errore: La versione '$VERSION' è già presente su ECR."
        exit 1
      fi
    
      # Solo per main: verifichiamo su S3
      FOUND=$(aws s3 ls "s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/" 2>/dev/null | wc -l || echo 0)
      echo "DEBUG FOUND = $FOUND"
    
      if [[ "$FOUND" -gt 0 ]]; then
        echo "Versione già presente su S3. Interrompo la pipeline."
        exit 1
      else
        echo "Versione non presente su S3. Procedo..."
      fi
    else
      # Per develop: consentiamo SNAPSHOT ma controlliamo se esiste già nella cartella develop
      if [[ "$VERSION" != *"SNAPSHOT"* ]]; then
        echo "Avviso: Versione '$VERSION' in 'develop' non è una SNAPSHOT. Consigliato usare suffisso -SNAPSHOT."
      fi
    
      # Verifica su S3 nel percorso develop
      FOUND=$(aws s3 ls "s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/${VERSION}/" 2>/dev/null | wc -l || echo 0)
      echo "DEBUG FOUND = $FOUND"
    
      if [[ "$FOUND" -gt 0 ]]; then
        echo "Versione già presente su S3 nel percorso develop. Sovrascrivo..."
      fi
    fi

build:
  stage: build
  dependencies:
    - extract_module_name
  script:
    - echo "Build del modulo $MODULE_NAME..."
    - mvn clean package -Psit -DskipTests
    # Crea un file manifest che descrive questa build
    - |
      if [ -f module_name.env ]; then
        . module_name.env
      fi
      cat > target/build-info.json <<EOF
      {
        "moduleName": "$MODULE_NAME",
        "version": "$VERSION",
        "buildDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
        "branch": "$CI_COMMIT_REF_NAME",
        "commitHash": "$CI_COMMIT_SHA"
      }
      EOF
  artifacts:
    paths:
      - target/*.jar
      - target/distribution/
      - target/build-info.json

test:
  stage: test
  dependencies:
    - extract_module_name
    - build
  script:
    - echo "Test del modulo $MODULE_NAME..."
    - mvn test

artifact_upload_s3:
  stage: artifact_upload_s3
  image:
    name: amazon/aws-cli:latest
    entrypoint: [""]
  dependencies:
    - build
    - extract_module_name
  script: |
    echo "Caricamento degli artefatti su S3..."
    
    # Carica le variabili dall'environment file
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Determina il percorso di destinazione in base al branch
    if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      S3_DESTINATION="s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/"
    else
      S3_DESTINATION="s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/${VERSION}/"
    fi
    
    # Carica i file su S3
    echo "Caricamento su ${S3_DESTINATION}..."
    aws s3 cp target/*.jar ${S3_DESTINATION}
    
    if [ -d "target/distribution/" ]; then
      aws s3 cp --recursive target/distribution/ ${S3_DESTINATION}distribution/
    fi
    
    # Carica il file build-info.json
    aws s3 cp target/build-info.json ${S3_DESTINATION}
    
    # Pulizia delle vecchie versioni, conservando solo le ultime 5
    echo "Pulizia delle versioni obsolete..."
    
    # Funzione per pulire le versioni, mantenendo solo le ultime N
    cleanup_versions() {
      local path=$1
      local keep=$2
    
      # Elenca le versioni, escludi le cartelle correnti e ordina per data (più recenti prima)
      versions=$(aws s3 ls ${path} | grep -v "${VERSION}/" | awk '{print $2}' | sort -r)
    
      # Conta le versioni
      count=$(echo "$versions" | wc -l)
    
      # Se abbiamo più versioni rispetto a quante ne vogliamo conservare
      if [ "$count" -gt "$keep" ]; then
        # Skippa le prime $keep versioni (le più recenti) e cancella le altre
        echo "$versions" | tail -n +$((keep + 1)) | while read -r old_version; do
          echo "Rimuovo la versione obsoleta: ${path}${old_version}"
          aws s3 rm --recursive "${path}${old_version}"
        done
      fi
    }
    
    # Esegui la pulizia specifica per il branch
    if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      # Per main, conserva le ultime 5 versioni
      cleanup_versions "s3://${S3_BUCKET_NAME}/${MODULE_NAME}/" 5
    else
      # Per develop, conserva le ultime 3 versioni
      cleanup_versions "s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/" 3
    fi   

build_docker:
  stage: build_docker
  tags:
    - ec2-shell
  dependencies:
    - extract_module_name
    - artifact_upload_s3
  only:
    - main
  script: |
    set -e  # Interrompe l'esecuzione in caso di errore
    
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Solo per main, non creare docker per versioni SNAPSHOT
    if [[ "$VERSION" == *"SNAPSHOT"* ]]; then
      echo "Attenzione: Versione SNAPSHOT rilevata su main. Non costruisco l'immagine Docker."
      exit 1
    fi
    
    echo "Costruzione dell'immagine Docker per $MODULE_NAME:$VERSION"
    
    # Verifica configurazione AWS
    aws --version
    aws sts get-caller-identity
    docker --version
    
    # Configurazione AWS CLI per ECR
    aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
    
    # Crea repository ECR se non esiste
    aws ecr describe-repositories --repository-names auxdromos-$MODULE_NAME || aws ecr create-repository --repository-name auxdromos-$MODULE_NAME
    
    # Recupera gli artefatti da S3
    mkdir -p ./artifacts/
    aws s3 cp "s3://$S3_BUCKET_NAME/$MODULE_NAME/$VERSION/" ./artifacts/ --recursive
    
    # Copia il Dockerfile nella directory di lavoro se non è presente
    if [ ! -f Dockerfile ] && [ -f ./artifacts/Dockerfile ]; then
      cp ./artifacts/Dockerfile ./
    fi
    
    # Costruisci e pubblica l'immagine Docker
    docker build -t auxdromos-$MODULE_NAME:$VERSION .
    docker tag auxdromos-$MODULE_NAME:$VERSION $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/auxdromos-$MODULE_NAME:$VERSION
    docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/auxdromos-$MODULE_NAME:$VERSION    
    

deploy_sit:
  stage: deploy_sit
  image:
    name: amazon/aws-cli:latest
    entrypoint: [""]
  dependencies:
    - build_docker  # Manteniamo questa dipendenza se esiste
    - artifact_upload_s3
  script: |
    set -e
    set -o pipefail
    
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Installiamo ssh per connetterci all'istanza EC2
    apt-get update && apt-get install -y openssh-client
    
    # Creiamo una directory temporanea per la chiave SSH
    mkdir -p ~/.ssh
    echo "$EC2_PRIVATE_KEY" > ~/.ssh/id_rsa
    chmod 600 ~/.ssh/id_rsa
    
    # Aggiungiamo l'host alla lista dei known_hosts per evitare prompt
    ssh-keyscan -H $EC2_HOST >> ~/.ssh/known_hosts
    
    # Verifichiamo se il modulo è "auxdromos-distro" che ha una gestione speciale
    if [ "$MODULE_NAME" == "auxdromos-distro" ]; then
      echo "Rilevato modulo di distribuzione, i file sono già sull'istanza"
    
      # Eseguiamo lo script di deploy usando i file già presenti
      ssh EC2_USER@$EC2_HOST "cd /opt/auxdromos/$MODULE_NAME/latest && unzip -o $MODULE_NAME-*.zip -d temp && cd temp && ./scripts/deploy_sit.sh $VERSION"
    else
      echo "Deploy standard per modulo $MODULE_NAME versione $VERSION..."
    
      # Per altri moduli, potremmo dover scaricare da S3 o eseguire altre operazioni
      # (questa parte dipende dalla logica attuale dello stage deploy_sit)
    
      # Esempio di download da S3 se necessario
      if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
        S3_PATH="s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/"
      else
        S3_PATH="s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/${VERSION}/"
      fi
    
      # Creiamo una directory temporanea sull'istanza
      ssh EC2_USER@$EC2_HOST "mkdir -p /tmp/deploy-$MODULE_NAME"
    
      # Copiamo i file necessari da S3 all'istanza, se non sono già presenti
      aws s3 cp "${S3_PATH}" "/tmp/" --recursive
      scp /tmp/*.jar "EC2_USER@$EC2_HOST:/tmp/deploy-$MODULE_NAME/"
    
      # Eseguiamo il deployment
      ssh EC2_USER@$EC2_HOST "cd /tmp/deploy-$MODULE_NAME && ./deploy.sh"
    fi
    
    echo "Deploy completato con successo!"
  environment:
    name: SIT
  only:
    - main

