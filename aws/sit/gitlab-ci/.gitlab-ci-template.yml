image: maven:3.9.9-amazoncorretto-17

stages:
  - prepare
  - check_version
  - build
  - test
  - artifact_upload_s3
  - build_docker
  - deploy_sit

# Rimuovo l'inclusione duplicata del template di security

extract_module_name:
  stage: prepare
  script: |
    echo "Estrazione del MODULE_NAME dal pom.xml..."
    export MODULE_NAME=$(grep "<artifactId>" pom.xml | head -1 | sed 's/[<>]/|/g' | cut -d'|' -f3)
    if [ -z "$MODULE_NAME" ]; then 
      echo "Errore: impossibile estrarre MODULE_NAME dal pom.xml"
      exit 1
    fi
    echo "MODULE_NAME estratto: $MODULE_NAME"
    echo "MODULE_NAME=$MODULE_NAME" >> module_name.env
    
    # Estrai anche la versione
    export VERSION=$(grep "<version>" pom.xml | head -1 | sed 's/[<>]/|/g' | cut -d'|' -f3)
    echo "VERSION=$VERSION" >> module_name.env
    echo "VERSION estratta: $VERSION"
    
    # Aggiungi informazioni sul branch
    echo "CI_COMMIT_REF_NAME=$CI_COMMIT_REF_NAME" >> module_name.env
  artifacts:
    reports:
      dotenv: module_name.env

check_version:
  stage: check_version
  dependencies:
    - extract_module_name
  image:
    name: amazon/aws-cli:latest
    entrypoint: [""]
  script: |
    set -e
    set -o pipefail

    echo "Verifica della versione..."

    # Carichiamo VERSION dal file .env creato prima
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Regole diverse per branch diversi
    if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      # Solo per main: vietiamo l'uso di SNAPSHOT
      if [[ "$VERSION" == *"SNAPSHOT"* ]]; then
        echo "Errore: Versione '$VERSION' non valida in 'main' (SNAPSHOT non consentito)."
        exit 1
      fi
    
      # Solo per main: verifichiamo su ECR
      if aws ecr describe-images --repository-name auxdromos-$MODULE_NAME --image-ids imageTag=$VERSION --region $AWS_DEFAULT_REGION > /dev/null 2>&1; then
        echo "Errore: La versione '$VERSION' è già presente su ECR."
        exit 1
      fi
    
      # Solo per main: verifichiamo su S3
      FOUND=$(aws s3 ls "s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/" 2>/dev/null | wc -l || echo 0)
      echo "DEBUG FOUND = $FOUND"
    
      if [[ "$FOUND" -gt 0 ]]; then
        echo "Versione già presente su S3. Interrompo la pipeline."
        exit 1
      else
        echo "Versione non presente su S3. Procedo..."
      fi
    else
      # Per develop: consentiamo SNAPSHOT ma controlliamo se esiste già nella cartella develop
      if [[ "$VERSION" != *"SNAPSHOT"* ]]; then
        echo "Avviso: Versione '$VERSION' in 'develop' non è una SNAPSHOT. Consigliato usare suffisso -SNAPSHOT."
      fi
    
      # Verifica su S3 nel percorso develop
      FOUND=$(aws s3 ls "s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/${VERSION}/" 2>/dev/null | wc -l || echo 0)
      echo "DEBUG FOUND = $FOUND"
    
      if [[ "$FOUND" -gt 0 ]]; then
        echo "Versione già presente su S3 nel percorso develop. Sovrascrivo..."
      fi
    fi

build:
  stage: build
  dependencies:
    - extract_module_name
  script:
    - echo "Build del modulo $MODULE_NAME..."
    - mvn clean package -Psit -DskipTests
    # Crea un file manifest che descrive questa build
    - |
      if [ -f module_name.env ]; then
        . module_name.env
      fi
      cat > target/build-info.json <<EOF
      {
        "moduleName": "$MODULE_NAME",
        "version": "$VERSION",
        "buildDate": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
        "branch": "$CI_COMMIT_REF_NAME",
        "commitHash": "$CI_COMMIT_SHA"
      }
      EOF
  artifacts:
    paths:
      - target/*.jar
      - target/distribution/
      - target/build-info.json

test:
  stage: test
  dependencies:
    - extract_module_name
    - build
  script:
    - echo "Test del modulo $MODULE_NAME..."
    - mvn test

artifact_upload_s3:
  stage: artifact_upload_s3
  image:
    name: amazon/aws-cli:latest
    entrypoint: [""]
  dependencies:
    - build
    - extract_module_name
  script: |
    echo "Caricamento degli artefatti su S3..."
    
    # Carica le variabili dall'environment file
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Determina il percorso di destinazione in base al branch
    if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      S3_DESTINATION="s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/"
    else
      S3_DESTINATION="s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/${VERSION}/"
    fi
    
    # Carica i file su S3
    echo "Caricamento su ${S3_DESTINATION}..."
    aws s3 cp target/*.jar ${S3_DESTINATION}
    
    if [ -d "target/distribution/" ]; then
      aws s3 cp --recursive target/distribution/ ${S3_DESTINATION}distribution/
    fi
    
    # Carica il file build-info.json
    aws s3 cp target/build-info.json ${S3_DESTINATION}
    
    # Pulizia delle vecchie versioni, conservando solo le ultime 5
    echo "Pulizia delle versioni obsolete..."
    
    # Funzione per pulire le versioni, mantenendo solo le ultime N
    cleanup_versions() {
      local path=$1
      local keep=$2
    
      # Elenca le versioni, escludi le cartelle correnti e ordina per data (più recenti prima)
      versions=$(aws s3 ls ${path} | grep -v "${VERSION}/" | awk '{print $2}' | sort -r)
    
      # Conta le versioni
      count=$(echo "$versions" | wc -l)
    
      # Se abbiamo più versioni rispetto a quante ne vogliamo conservare
      if [ "$count" -gt "$keep" ]; then
        # Skippa le prime $keep versioni (le più recenti) e cancella le altre
        echo "$versions" | tail -n +$((keep + 1)) | while read -r old_version; do
          echo "Rimuovo la versione obsoleta: ${path}${old_version}"
          aws s3 rm --recursive "${path}${old_version}"
        done
      fi
    }
    
    # Esegui la pulizia specifica per il branch
    if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      # Per main, conserva le ultime 5 versioni
      cleanup_versions "s3://${S3_BUCKET_NAME}/${MODULE_NAME}/" 5
    else
      # Per develop, conserva le ultime 3 versioni
      cleanup_versions "s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/" 3
    fi   

build_docker:
  stage: build_docker
  tags:
    - ec2-shell
  dependencies:
    - extract_module_name
    - artifact_upload_s3
  only:
    - main
  script: |
    set -e  # Interrompe l'esecuzione in caso di errore
    
    if [ -f module_name.env ]; then
      . module_name.env
    fi
    
    # Solo per main, non creare docker per versioni SNAPSHOT
    if [[ "$VERSION" == *"SNAPSHOT"* ]]; then
      echo "Attenzione: Versione SNAPSHOT rilevata su main. Non costruisco l'immagine Docker."
      exit 1
    fi
    
    echo "Costruzione dell'immagine Docker per $MODULE_NAME:$VERSION"
    
    # Verifica configurazione AWS
    aws --version
    aws sts get-caller-identity
    docker --version
    
    # Configurazione AWS CLI per ECR
    aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
    
    # Crea repository ECR se non esiste
    aws ecr describe-repositories --repository-names auxdromos-$MODULE_NAME || aws ecr create-repository --repository-name auxdromos-$MODULE_NAME
    
    # Recupera gli artefatti da S3
    mkdir -p ./artifacts/
    aws s3 cp "s3://$S3_BUCKET_NAME/$MODULE_NAME/$VERSION/" ./artifacts/ --recursive
    
    # Copia il Dockerfile nella directory di lavoro se non è presente
    if [ ! -f Dockerfile ] && [ -f ./artifacts/Dockerfile ]; then
      cp ./artifacts/Dockerfile ./
    fi
    
    # Costruisci e pubblica l'immagine Docker
    docker build -t auxdromos-$MODULE_NAME:$VERSION .
    docker tag auxdromos-$MODULE_NAME:$VERSION $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/auxdromos-$MODULE_NAME:$VERSION
    docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/auxdromos-$MODULE_NAME:$VERSION    
    

deploy_sit:
  stage: deploy_sit
  image:
    name: amazon/aws-cli:latest
    entrypoint: [""]
  dependencies:
    - extract_module_name
  script:
    - echo "Esecuzione del deploy in ambiente SIT..."
    - if [ -f module_name.env ]; then . module_name.env; fi
    - echo "Modulo da deployare $MODULE_NAME versione $VERSION"

    # Installazione delle dipendenze necessarie
    - apt-get update -y && apt-get install -y unzip docker.io docker-compose curl jq

    # 1. Download dell'artefatto distro più recente
    - echo "Download dell'artefatto distro da S3..."
    - DISTRO_VERSION=$(aws s3 ls s3://auxdromos-artifacts-unique/distro/ --recursive | grep manifest.json | sort -r | head -1 | awk -F'/' '{print $2}')
    - echo "Ultima versione di distro trovata $DISTRO_VERSION"
    - mkdir -p distro
    - aws s3 cp s3://auxdromos-artifacts-unique/distro/$DISTRO_VERSION/distro-$DISTRO_VERSION.zip distro/

    # 2. Estrazione dell'artefatto distro
    - echo "Estrazione dell'artefatto distro..."
    - cd distro
    - unzip -o distro-$DISTRO_VERSION.zip
    - echo "Struttura dei file estratti:"
    - find . -type f | sort | head -20
    - cd ..

    # 3. Download dell'artefatto del modulo corrente
    - echo "Download degli artefatti di $MODULE_NAME da S3..."
    - if [ "$CI_COMMIT_REF_NAME" == "main" ]; then
      S3_PATH="s3://${S3_BUCKET_NAME}/${MODULE_NAME}/${VERSION}/";
      else
      S3_PATH="s3://${S3_BUCKET_NAME}/develop/${MODULE_NAME}/${VERSION}/";
      fi
    - mkdir -p deployment
    - aws s3 cp $S3_PATH deployment/ --recursive
    - echo "Artefatti scaricati:"
    - ls -la deployment/

    # 4. Ricerca dello script di deploy
    - echo "Ricerca dello script di deploy..."
    - cd distro
    - SCRIPT_PATH=$(find . -name "deploy_module.sh" | grep -E "aws/sit/script" | head -1)
    - cd ..
    - echo "Script path trovato $SCRIPT_PATH"

    # Verifica se lo script è stato trovato e procedere con il deploy
    - if [ -n "$SCRIPT_PATH" ]; then
      echo "Script di deploy trovato distro/$SCRIPT_PATH"
      chmod +x distro/$SCRIPT_PATH
      
      # Identificazione della directory base corretta
      DEPLOY_SCRIPT_DIR=$(dirname "distro/$SCRIPT_PATH")
      BASE_DIR=$(echo $DEPLOY_SCRIPT_DIR | sed 's|/aws/sit/script||')
      echo "Directory base rilevata $BASE_DIR"
      
      # 5. Preparazione ambiente per deploy_module.sh
      mkdir -p $BASE_DIR/env
      echo "AWS_ACCOUNT_ID=${AWS_ACCOUNT_ID}" > $BASE_DIR/env/deploy.env
      echo "AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}" >> $BASE_DIR/env/deploy.env
      echo "BASE_PATH=$(pwd)/$BASE_DIR" >> $BASE_DIR/env/deploy.env
      echo "MODULES=\"rdbms api-gateway frontend backend\"" >> $BASE_DIR/env/deploy.env
      echo "MODULE_ORDER=\"rdbms api-gateway backend frontend\"" >> $BASE_DIR/env/deploy.env
      
      # 6. Copia degli artefatti del modulo dove il deploy_module.sh se li aspetta
      cp -r deployment/* $BASE_DIR/
      
      # 7. Esecuzione dello script con parametro corretto
      cd $(dirname "distro/$SCRIPT_PATH")
      ./$(basename $SCRIPT_PATH) $MODULE_NAME
      else
      echo "ATTENZIONE Script di deploy deploy_module.sh non trovato nel pacchetto distro"
      # Esplora la struttura per debug
      echo "File .sh disponibili nell'archivio distro:"
      find distro -type f -name "*.sh" | sort
      exit 1  # Fallisce la pipeline se lo script non viene trovato
      fi

    - echo "Deploy in ambiente SIT completato con successo"
  environment:
    name: SIT
  only:
    - main
